{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VILhGf24C6IY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "def load_mnist(flatten=True, normalize=True, one_hot=True, num_classes=10):\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    if flatten:\n",
        "        x_train = x_train.reshape(x_train.shape[0], -1)\n",
        "        x_test = x_test.reshape(x_test.shape[0], -1)\n",
        "    if normalize:\n",
        "        x_train = x_train / 255.0\n",
        "        x_test = x_test / 255.0\n",
        "    if one_hot:\n",
        "        y_train = np.eye(num_classes)[y_train]\n",
        "        y_test = np.eye(num_classes)[y_test]\n",
        "    return x_train, y_train, x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def relu(z):\n",
        "    return np.maximum(0, z)\n",
        "def relu_der(z):\n",
        "    return (z > 0).astype(float)\n",
        "def soft(z):\n",
        "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)"
      ],
      "metadata": {
        "id": "1cifNa8fDmhN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ini_para(layer_sizes):\n",
        "    np.random.seed(42)\n",
        "    params = {}\n",
        "    L = len(layer_sizes)\n",
        "    for l in range(1, L):\n",
        "        params['W'+str(l)] = np.random.randn(layer_sizes[l-1], layer_sizes[l]) * 0.01\n",
        "        params['b'+str(l)] = np.zeros((1, layer_sizes[l]))\n",
        "    return params"
      ],
      "metadata": {
        "id": "-UXYYhTCDoYD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(X, params):\n",
        "    cache = {'A0': X}\n",
        "    L = len(params)//2\n",
        "    for l in range(1, L):\n",
        "        Z = np.dot(cache['A'+str(l-1)], params['W'+str(l)]) + params['b'+str(l)]\n",
        "        A = relu(Z)\n",
        "        cache['Z'+str(l)] = Z\n",
        "        cache['A'+str(l)] = A\n",
        "    ZL = np.dot(cache['A'+str(L-1)], params['W'+str(L)]) + params['b'+str(L)]\n",
        "    AL = soft(ZL)\n",
        "    cache['Z'+str(L)] = ZL\n",
        "    cache['A'+str(L)] = AL\n",
        "    return AL, cache"
      ],
      "metadata": {
        "id": "Vq9BhFvIDqgy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def comp_loss(Y_pred, Y_true):\n",
        "    m = Y_true.shape[0]\n",
        "    loss = -np.sum(Y_true * np.log(Y_pred + 1e-8)) / m\n",
        "    return loss"
      ],
      "metadata": {
        "id": "x0PBnn7tDsgm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backward(Y_pred, Y_true, params, cache, learning_rate=0.01):\n",
        "    grads = {}\n",
        "    L = len(params)//2\n",
        "    m = Y_true.shape[0]\n",
        "    dZ = Y_pred - Y_true\n",
        "    grads['dW'+str(L)] = np.dot(cache['A'+str(L-1)].T, dZ)/m\n",
        "    grads['db'+str(L)] = np.sum(dZ, axis=0, keepdims=True)/m\n",
        "    dA_prev = np.dot(dZ, params['W'+str(L)].T)\n",
        "    for l in reversed(range(1, L)):\n",
        "        dZ = dA_prev * relu_der(cache['Z'+str(l)])\n",
        "        grads['dW'+str(l)] = np.dot(cache['A'+str(l-1)].T, dZ)/m\n",
        "        grads['db'+str(l)] = np.sum(dZ, axis=0, keepdims=True)/m\n",
        "        if l > 1:\n",
        "            dA_prev = np.dot(dZ, params['W'+str(l)].T)\n",
        "    for l in range(1, L+1):\n",
        "        params['W'+str(l)] -= learning_rate * grads['dW'+str(l)]\n",
        "        params['b'+str(l)] -= learning_rate * grads['db'+str(l)]"
      ],
      "metadata": {
        "id": "gxe0wkzPDuNz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X_train, Y_train, X_test, Y_test, hidden_layers=[128,64], lr=0.01, epochs=20):\n",
        "    layer_sizes = [X_train.shape[1]] + hidden_layers + [10]\n",
        "    params = ini_para(layer_sizes)\n",
        "    for epoch in range(epochs):\n",
        "        Y_pred, cache = forward(X_train, params)\n",
        "        loss = comp_loss(Y_pred, Y_train)\n",
        "        backward(Y_pred, Y_train, params, cache, learning_rate=lr)\n",
        "        if (epoch+1) % 5 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}\")\n",
        "    Y_pred_test, _ = forward(X_test, params)\n",
        "    accuracy = np.mean(np.argmax(Y_pred_test, axis=1) == np.argmax(Y_test, axis=1))\n",
        "    print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
        "    return params"
      ],
      "metadata": {
        "id": "T9S0nZr4DwK6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import wandb\n",
        "wandb.init(\n",
        "    project=\"mnist-q8_a\",\n",
        "    name=\"CE_vs_Squared_Error\"\n",
        ")\n",
        "from keras.datasets import mnist\n",
        "def load_mnist(flatten=True, normalize=True, one_hot=True, num_classes=10):\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    if flatten:\n",
        "        x_train = x_train.reshape(x_train.shape[0], -1)\n",
        "        x_test = x_test.reshape(x_test.shape[0], -1)\n",
        "    if normalize:\n",
        "        x_train = x_train / 255.0\n",
        "        x_test = x_test / 255.0\n",
        "    if one_hot:\n",
        "        y_train = np.eye(num_classes)[y_train]\n",
        "        y_test = np.eye(num_classes)[y_test]\n",
        "    return x_train, y_train, x_test, y_test\n",
        "class Activate:\n",
        "    @staticmethod\n",
        "    def relu(Z):\n",
        "        return np.maximum(0, Z)\n",
        "    @staticmethod\n",
        "    def relu_der(Z):\n",
        "        return (Z > 0).astype(float)\n",
        "    @staticmethod\n",
        "    def softmax(Z):\n",
        "        expZ = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
        "        return expZ / np.sum(expZ, axis=1, keepdims=True)\n",
        "class FNN:\n",
        "    def __init__(self, input_size, hidden_layers, output_size, seed=42):\n",
        "        np.random.seed(seed)\n",
        "        self.layers = [input_size] + hidden_layers + [output_size]\n",
        "        self.L = len(self.layers) - 1\n",
        "        self.weights = {}\n",
        "        self.biases = {}\n",
        "        for l in range(1, self.L+1):\n",
        "            limit = np.sqrt(6 / (self.layers[l-1] + self.layers[l]))\n",
        "            self.weights['W'+str(l)] = np.random.uniform(-limit, limit, (self.layers[l-1], self.layers[l]))\n",
        "            self.biases['b'+str(l)] = np.zeros((1, self.layers[l]))\n",
        "        self.opt_caches = {}\n",
        "    def forward(self, X):\n",
        "        self.cache = {'A0': X}\n",
        "        for l in range(1, self.L):\n",
        "            Z = np.dot(self.cache['A'+str(l-1)], self.weights['W'+str(l)]) + self.biases['b'+str(l)]\n",
        "            A = Activate.relu(Z)\n",
        "            self.cache['Z'+str(l)] = Z\n",
        "            self.cache['A'+str(l)] = A\n",
        "        ZL = np.dot(self.cache['A'+str(self.L-1)], self.weights['W'+str(self.L)]) + self.biases['b'+str(self.L)]\n",
        "        AL = Activate.softmax(ZL)\n",
        "        self.cache['Z'+str(self.L)] = ZL\n",
        "        self.cache['A'+str(self.L)] = AL\n",
        "        return AL\n",
        "    def backward(self, Y_true, loss_type=\"cross_entropy\"):\n",
        "        m = Y_true.shape[0]\n",
        "        self.grads = {}\n",
        "        Y_pred = self.cache['A'+str(self.L)]\n",
        "        if loss_type == \"cross_entropy\":\n",
        "          dZ = Y_pred - Y_true\n",
        "        elif loss_type == \"squared_error\":\n",
        "          dZ = (Y_pred - Y_true) * Y_pred * (1 - Y_pred)\n",
        "\n",
        "        self.grads['dW'+str(self.L)] = np.dot(self.cache['A'+str(self.L-1)].T, dZ)/m\n",
        "        self.grads['db'+str(self.L)] = np.sum(dZ, axis=0, keepdims=True)/m\n",
        "        dA_prev = np.dot(dZ, self.weights['W'+str(self.L)].T)\n",
        "        for l in reversed(range(1, self.L)):\n",
        "            dZ = dA_prev * Activate.relu_der(self.cache['Z'+str(l)])\n",
        "            self.grads['dW'+str(l)] = np.dot(self.cache['A'+str(l-1)].T, dZ)/m\n",
        "            self.grads['db'+str(l)] = np.sum(dZ, axis=0, keepdims=True)/m\n",
        "            if l > 1:\n",
        "                dA_prev = np.dot(dZ, self.weights['W'+str(l)].T)\n",
        "    def update_parameters(self, lr=0.01, optimizer='sgd', beta1=0.9, beta2=0.999, epsilon=1e-8, t=1):\n",
        "        for l in range(1, self.L+1):\n",
        "            dW = self.grads['dW'+str(l)]\n",
        "            db = self.grads['db'+str(l)]\n",
        "            if optimizer == 'sgd':\n",
        "                self.weights['W'+str(l)] -= lr * dW\n",
        "                self.biases['b'+str(l)] -= lr * db\n",
        "            elif optimizer == 'momentum':\n",
        "                if 'vW'+str(l) not in self.opt_caches:\n",
        "                    self.opt_caches['vW'+str(l)] = np.zeros_like(dW)\n",
        "                    self.opt_caches['vb'+str(l)] = np.zeros_like(db)\n",
        "                self.opt_caches['vW'+str(l)] = beta1*self.opt_caches['vW'+str(l)] + (1-beta1)*dW\n",
        "                self.opt_caches['vb'+str(l)] = beta1*self.opt_caches['vb'+str(l)] + (1-beta1)*db\n",
        "                self.weights['W'+str(l)] -= lr * self.opt_caches['vW'+str(l)]\n",
        "                self.biases['b'+str(l)] -= lr * self.opt_caches['vb'+str(l)]\n",
        "            elif optimizer == 'nesterov':\n",
        "                if 'vW'+str(l) not in self.opt_caches:\n",
        "                    self.opt_caches['vW'+str(l)] = np.zeros_like(dW)\n",
        "                    self.opt_caches['vb'+str(l)] = np.zeros_like(db)\n",
        "                vW_prev = self.opt_caches['vW'+str(l)].copy()\n",
        "                vb_prev = self.opt_caches['vb'+str(l)].copy()\n",
        "                self.opt_caches['vW'+str(l)] = beta1*self.opt_caches['vW'+str(l)] + lr*dW\n",
        "                self.opt_caches['vb'+str(l)] = beta1*self.opt_caches['vb'+str(l)] + lr*db\n",
        "                self.weights['W'+str(l)] -= beta1*vW_prev + (1+beta1)*(self.opt_caches['vW'+str(l)] - vW_prev)\n",
        "                self.biases['b'+str(l)] -= beta1*vb_prev + (1+beta1)*(self.opt_caches['vb'+str(l)] - vb_prev)\n",
        "            elif optimizer == 'rmsprop':\n",
        "                if 'sW'+str(l) not in self.opt_caches:\n",
        "                    self.opt_caches['sW'+str(l)] = np.zeros_like(dW)\n",
        "                    self.opt_caches['sb'+str(l)] = np.zeros_like(db)\n",
        "                self.opt_caches['sW'+str(l)] = beta2*self.opt_caches['sW'+str(l)] + (1-beta2)*(dW**2)\n",
        "                self.opt_caches['sb'+str(l)] = beta2*self.opt_caches['sb'+str(l)] + (1-beta2)*(db**2)\n",
        "                self.weights['W'+str(l)] -= lr * dW / (np.sqrt(self.opt_caches['sW'+str(l)]) + epsilon)\n",
        "                self.biases['b'+str(l)] -= lr * db / (np.sqrt(self.opt_caches['sb'+str(l)]) + epsilon)\n",
        "            elif optimizer == 'adam':\n",
        "                if 'vW'+str(l) not in self.opt_caches:\n",
        "                    self.opt_caches['vW'+str(l)] = np.zeros_like(dW)\n",
        "                    self.opt_caches['vb'+str(l)] = np.zeros_like(db)\n",
        "                    self.opt_caches['sW'+str(l)] = np.zeros_like(dW)\n",
        "                    self.opt_caches['sb'+str(l)] = np.zeros_like(db)\n",
        "                self.opt_caches['vW'+str(l)] = beta1*self.opt_caches['vW'+str(l)] + (1-beta1)*dW\n",
        "                self.opt_caches['vb'+str(l)] = beta1*self.opt_caches['vb'+str(l)] + (1-beta1)*db\n",
        "                self.opt_caches['sW'+str(l)] = beta2*self.opt_caches['sW'+str(l)] + (1-beta2)*(dW**2)\n",
        "                self.opt_caches['sb'+str(l)] = beta2*self.opt_caches['sb'+str(l)] + (1-beta2)*(db**2)\n",
        "                vW_corr = self.opt_caches['vW'+str(l)] / (1 - beta1**t)\n",
        "                vb_corr = self.opt_caches['vb'+str(l)] / (1 - beta1**t)\n",
        "                sW_corr = self.opt_caches['sW'+str(l)] / (1 - beta2**t)\n",
        "                sb_corr = self.opt_caches['sb'+str(l)] / (1 - beta2**t)\n",
        "                self.weights['W'+str(l)] -= lr * vW_corr / (np.sqrt(sW_corr) + epsilon)\n",
        "                self.biases['b'+str(l)] -= lr * vb_corr / (np.sqrt(sb_corr) + epsilon)\n",
        "            elif optimizer == 'nadam':\n",
        "                if 'vW'+str(l) not in self.opt_caches:\n",
        "                    self.opt_caches['vW'+str(l)] = np.zeros_like(dW)\n",
        "                    self.opt_caches['vb'+str(l)] = np.zeros_like(db)\n",
        "                    self.opt_caches['sW'+str(l)] = np.zeros_like(dW)\n",
        "                    self.opt_caches['sb'+str(l)] = np.zeros_like(db)\n",
        "                vW_prev = self.opt_caches['vW'+str(l)].copy()\n",
        "                vb_prev = self.opt_caches['vb'+str(l)].copy()\n",
        "                self.opt_caches['vW'+str(l)] = beta1*self.opt_caches['vW'+str(l)] + (1-beta1)*dW\n",
        "                self.opt_caches['vb'+str(l)] = beta1*self.opt_caches['vb'+str(l)] + (1-beta1)*db\n",
        "                self.opt_caches['sW'+str(l)] = beta2*self.opt_caches['sW'+str(l)] + (1-beta2)*(dW**2)\n",
        "                self.opt_caches['sb'+str(l)] = beta2*self.opt_caches['sb'+str(l)] + (1-beta2)*(db**2)\n",
        "                vW_corr = (beta1*vW_prev + (1+beta1)*self.opt_caches['vW'+str(l)]/(1-beta1**t)) / (1 - beta1**t)\n",
        "                vb_corr = (beta1*vb_prev + (1+beta1)*self.opt_caches['vb'+str(l)]/(1-beta1**t)) / (1 - beta1**t)\n",
        "                sW_corr = self.opt_caches['sW'+str(l)] / (1 - beta2**t)\n",
        "                sb_corr = self.opt_caches['sb'+str(l)] / (1 - beta2**t)\n",
        "                self.weights['W'+str(l)] -= lr * vW_corr / (np.sqrt(sW_corr) + epsilon)\n",
        "                self.biases['b'+str(l)] -= lr * vb_corr / (np.sqrt(sb_corr) + epsilon)\n",
        "    def cross_entropy_loss(self, Y_pred, Y_true):\n",
        "        m = Y_true.shape[0]\n",
        "        return -np.sum(Y_true*np.log(Y_pred + 1e-8))/m\n",
        "    def squared_error_loss(self, Y_pred, Y_true):\n",
        "        return np.mean(np.sum((Y_pred - Y_true) ** 2, axis=1))\n",
        "    def compute_loss(self, Y_pred, Y_true):\n",
        "        return self.cross_entropy_loss(Y_pred, Y_true)\n",
        "    def train(self, X_train, Y_train, X_test, Y_test, epochs=10, batch_size=64, lr=0.01, optimizer='sgd'):\n",
        "        num_samples = X_train.shape[0]\n",
        "        loss_history_ce = []\n",
        "        loss_history_se = []\n",
        "        for epoch in range(epochs):\n",
        "          perm = np.random.permutation(num_samples)\n",
        "          X_shuf, Y_shuf = X_train[perm], Y_train[perm]\n",
        "          epoch_ce, epoch_se, num_batches = 0, 0, 0\n",
        "          for i in range(0, num_samples, batch_size):\n",
        "            Xb = X_shuf[i:i+batch_size]\n",
        "            Yb = Y_shuf[i:i+batch_size]\n",
        "            Y_pred = self.forward(Xb)\n",
        "            loss_ce = self.cross_entropy_loss(Y_pred, Yb)\n",
        "            loss_se = self.squared_error_loss(Y_pred, Yb)\n",
        "            self.backward(Yb, loss_type=\"cross_entropy\")\n",
        "            self.update_parameters(lr=lr, optimizer=optimizer, t=epoch+1)\n",
        "            epoch_ce += loss_ce\n",
        "            epoch_se += loss_se\n",
        "            num_batches += 1\n",
        "          epoch_ce /= num_batches\n",
        "          epoch_se /= num_batches\n",
        "          loss_history_ce.append(epoch_ce)\n",
        "          loss_history_se.append(epoch_se)\n",
        "          Y_test_pred = self.forward(X_test)\n",
        "          test_acc = np.mean(\n",
        "          np.argmax(Y_test_pred, axis=1) == np.argmax(Y_test, axis=1)\n",
        "          )\n",
        "          wandb.log({\n",
        "              \"epoch\": epoch,\n",
        "              \"cross_entropy_loss\": epoch_ce,\n",
        "              \"squared_error_loss\": epoch_se,\n",
        "              \"test_accuracy\": test_acc\n",
        "          })\n",
        "        wandb.log({\n",
        "                \"loss_comparison\": wandb.plot.line_series(\n",
        "                xs=list(range(len(loss_history_ce))),\n",
        "                ys=[loss_history_ce, loss_history_se],\n",
        "                keys=[\"Cross Entropy\", \"Squared Error\"],\n",
        "                title=\"Loss Comparison: Cross-Entropy vs Squared Error\",\n",
        "                xname=\"Epoch\"\n",
        "                )\n",
        "                })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "4GVJwJxoDx1o",
        "outputId": "1e170ff5-60fd-4d0a-dc2b-e527cc43d4b5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Invalid choice\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 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\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmanees-6732\u001b[0m (\u001b[33mvaishalinir-ymc2022-chennai-institute-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.24.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260129_190113-1tt84xot</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q8_a/runs/1tt84xot' target=\"_blank\">CE_vs_Squared_Error</a></strong> to <a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q8_a' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q8_a' target=\"_blank\">https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q8_a</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q8_a/runs/1tt84xot' target=\"_blank\">https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q8_a/runs/1tt84xot</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train, X_test, Y_test = load_mnist()\n",
        "configs = [\n",
        "    {\n",
        "        \"name\": \"Config_1_Best_Overall\",\n",
        "        \"hidden_layers\": [128, 128, 128],\n",
        "        \"optimizer\": \"adam\",\n",
        "        \"lr\": 0.001,\n",
        "        \"batch_size\": 64\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Config_2_Deep_Feature\",\n",
        "        \"hidden_layers\": [128, 128, 128, 128, 128],\n",
        "        \"optimizer\": \"nadam\",\n",
        "        \"lr\": 0.001,\n",
        "        \"batch_size\": 64\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Config_3_Lightweight\",\n",
        "        \"hidden_layers\": [64, 64],\n",
        "        \"optimizer\": \"adam\",\n",
        "        \"lr\": 0.001,\n",
        "        \"batch_size\": 32\n",
        "    }\n",
        "]\n",
        "for cfg in configs:\n",
        "    wandb.init(\n",
        "        project=\"mnist-q10\",\n",
        "        name=cfg[\"name\"],\n",
        "        config=cfg\n",
        "    )\n",
        "    model = FNN(\n",
        "        input_size=784,\n",
        "        hidden_layers=cfg[\"hidden_layers\"],\n",
        "        output_size=10\n",
        "    )\n",
        "    model.train(\n",
        "        X_train, Y_train,\n",
        "        X_test, Y_test,\n",
        "        epochs=10,\n",
        "        batch_size=cfg[\"batch_size\"],\n",
        "        lr=cfg[\"lr\"],\n",
        "        optimizer=cfg[\"optimizer\"]\n",
        "    )\n",
        "    wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n-sLtfWEDzfY",
        "outputId": "db7cd24e-9f30-4a02-8686-e980fec700e2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.24.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260129_190745-exxinl2d</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10/runs/exxinl2d' target=\"_blank\">Config_1_Best_Overall</a></strong> to <a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10' target=\"_blank\">https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10/runs/exxinl2d' target=\"_blank\">https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10/runs/exxinl2d</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>cross_entropy_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>squared_error_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁▅▇▇▇▆████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>cross_entropy_loss</td><td>0.02489</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>squared_error_loss</td><td>0.01125</td></tr><tr><td>test_accuracy</td><td>0.9777</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Config_1_Best_Overall</strong> at: <a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10/runs/exxinl2d' target=\"_blank\">https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10/runs/exxinl2d</a><br> View project at: <a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10' target=\"_blank\">https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10</a><br>Synced 4 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260129_190745-exxinl2d/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.24.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260129_190908-k0yzllij</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10/runs/k0yzllij' target=\"_blank\">Config_2_Deep_Feature</a></strong> to <a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10' target=\"_blank\">https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10/runs/k0yzllij' target=\"_blank\">https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10/runs/k0yzllij</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>cross_entropy_loss</td><td>█▃▂▂▂▂▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>squared_error_loss</td><td>█▃▂▂▂▂▁▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁▅▆▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>cross_entropy_loss</td><td>0.11875</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>squared_error_loss</td><td>0.0544</td></tr><tr><td>test_accuracy</td><td>0.9513</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Config_2_Deep_Feature</strong> at: <a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10/runs/k0yzllij' target=\"_blank\">https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10/runs/k0yzllij</a><br> View project at: <a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10' target=\"_blank\">https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10</a><br>Synced 4 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260129_190908-k0yzllij/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.24.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260129_191136-hj93m8cm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10/runs/hj93m8cm' target=\"_blank\">Config_3_Lightweight</a></strong> to <a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10' target=\"_blank\">https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10/runs/hj93m8cm' target=\"_blank\">https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10/runs/hj93m8cm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>cross_entropy_loss</td><td>█▄▃▃▂▂▂▁▁▁</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>squared_error_loss</td><td>█▄▃▃▂▂▂▁▁▁</td></tr><tr><td>test_accuracy</td><td>▁▄▅▆▆▆▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>cross_entropy_loss</td><td>0.06365</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>squared_error_loss</td><td>0.02912</td></tr><tr><td>test_accuracy</td><td>0.9731</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Config_3_Lightweight</strong> at: <a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10/runs/hj93m8cm' target=\"_blank\">https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10/runs/hj93m8cm</a><br> View project at: <a href='https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10' target=\"_blank\">https://wandb.ai/vaishalinir-ymc2022-chennai-institute-of-technology/mnist-q10</a><br>Synced 4 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260129_191136-hj93m8cm/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}